{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0379c7f-e40d-4e14-9860-afee53844b41",
   "metadata": {},
   "source": [
    "Run all commands listed in requirements.txt, proper format wasn't working from pipreqs\n",
    "\n",
    "Also run the commented out nltk import & downloads exactly once to use newspaper's nlp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d3c5a454-e7b8-4008-b047-3c5139ac89a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import newspaper\n",
    "from nela_features.nela_features import NELAFeatureExtractor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jellyfish\n",
    "import tldextract\n",
    "import pickle\n",
    "# Run the below once\n",
    "#import nltk\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d930ddb7-590d-4f1f-b3ce-d71a6f43951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://theonion.com/announcement-of-fourth-child-contains-conspicuous-lack-of-exclamation-points/\"\n",
    "\n",
    "def get_article_text(url):\n",
    "    return newspaper.article(url).text\n",
    "\n",
    "def smog_to_text(smog):\n",
    "    if smog >= 17:\n",
    "        return \"Graduate\"\n",
    "    if smog >= 13:\n",
    "        return \"Undergraduate\"\n",
    "    if smog >= 9:\n",
    "        return \"High School\"\n",
    "    if smog >= 5:\n",
    "        return \"Middle School\"\n",
    "    else:\n",
    "        return \"Elementary School\"\n",
    "    \n",
    "def get_nela_smog(url):\n",
    "    text = get_article_text(url)\n",
    "    nela = NELAFeatureExtractor()\n",
    "\n",
    "    #feature_vector, feature_names = nela.extract_all(text)\n",
    "\n",
    "    #style_vector, style_names = nela.extract_style(text) \n",
    "    complexity_vector, complexity_names = nela.extract_complexity(text) \n",
    "    #bias_vector, bias_names = nela.extract_bias(text)\n",
    "    #affect_vector, affect_names = nela.extract_affect(text) \n",
    "    #moral_vector, moral_names = nela.extract_moral(text) \n",
    "    #event_vector, event_names = nela.extract_event(text)\n",
    "    #print(complexity_vector,complexity_names)\n",
    "    return smog_to_text(complexity_vector[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8dd5f402-749d-4fcb-9885-cb1c94d6c020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Middle School'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nela_smog(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "da2ee5b9-27c6-48f1-a0ce-bd92eb92c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using allsides ratings dataset found at https://www.kaggle.com/datasets/supratimhaldar/allsides-ratings-of-bias-in-electronic-media\n",
    "def get_allsides(url):\n",
    "    allsides = pd.read_csv('dataset/allsides.csv')\n",
    "    parsed = tldextract.extract(url)\n",
    "    website = parsed.domain\n",
    "    allsides_vals = allsides.values\n",
    "    sources = allsides_vals[:,0]\n",
    "    print(website)\n",
    "    #distances = [liquidmetal.score(website, x.lower()) for x in sources]\n",
    "    #print(max(distances))\n",
    "    distances = [jellyfish.levenshtein_distance(website, x.lower()) for x in sources]\n",
    "    loc = distances.index(min(distances))\n",
    "    source_allsides_format = sources[loc]\n",
    "    row = allsides_vals[loc]\n",
    "    return row\n",
    "def get_knn_class(url):\n",
    "    nela = NELAFeatureExtractor()\n",
    "    with open('knnfakenews.pkl', 'rb') as f:\n",
    "        knn = pickle.load(f)\n",
    "    text = get_article_text(url)\n",
    "    feature_vector, feature_names = nela.extract_all(text)\n",
    "    vector = [[feature_vector[i] for i in [24, 22, 4, 86]]]\n",
    "    print(knn.predict(vector))\n",
    "    return knn.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "766b6b55-284a-4bca-bb2e-3bad1b3ef362",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(allsides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bfe2d55c-6d04-410a-b96d-184ee8759846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nytimes\n",
      "['AllSides' 'allsides' 5875 4211 1664 2.5306490384615383 'Strongly Agrees'\n",
      " 'https://www.allsides.com/news-source/allsides']\n"
     ]
    }
   ],
   "source": [
    "print(get_allsides(\"https://www.nytimes.com/2024/11/26/world/middleeast/israel-oct-7-inquiry.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "515b1a8b-cd40-4332-ab41-70f57d8ed699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1, -10.598, 3.0, -34.02, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], ['quotes', 'exclaim', 'allpunc', 'allcaps', 'stops', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'WP$', 'WRB', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', '$', \"''\", '(', ')', ',', '--', '.', ':', '``', 'ttr', 'avg_wordlen', 'word_count', 'flesch_kincaid_grade_level', 'smog_index', 'coleman_liau_index', 'lix', 'bias_words', 'assertatives', 'factives', 'hedges', 'implicatives', 'report_verbs', 'positive_opinion_words', 'negative_opinion_words', 'vadneg', 'vadneu', 'vadpos', 'wneg', 'wpos', 'wneu', 'sneg', 'spos', 'sneu', 'HarmVirtue', 'HarmVice', 'FairnessVirtue', 'FairnessVice', 'IngroupVirtue', 'IngroupVice', 'AuthorityVirtue', 'AuthorityVice', 'PurityVirtue', 'PurityVice', 'MoralityGeneral', 'num_locations', 'num_dates'])\n"
     ]
    }
   ],
   "source": [
    "nela = NELAFeatureExtractor()\n",
    "print(nela.extract_all(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7886b806-40aa-47de-80c2-6ab37ed6215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn_class(\"https://www.nytimes.com/2024/11/26/world/middleeast/israel-oct-7-inquiry.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dd1cc45b-33e5-49ff-8e13-a895903d77a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn_class(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "518f5997-324a-44aa-8527-b94d3ab7befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_knn_class(\"https://www.cbsnews.com/news/tom-homan-greg-abbott-texas-border-visit/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9e1d18b1-741d-46af-9d5e-3ae0af909e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://skepticalinquirer.org/exclusive/are-saunas-good-for-you-yes-but/\"\n",
    "get_knn_class(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf0d66e-3d33-4344-91b0-a277703f5e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
