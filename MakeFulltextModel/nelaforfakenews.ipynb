{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bcea5d4-3c9f-4d73-8455-0eb653a7edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nela_features.nela_features import NELAFeatureExtractor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21431d97-16dd-465d-bacb-fcdd4062093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f26b68789c0468fad54c5c95e526ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_data=pd.read_csv(\"dataset/Fake.csv\")\n",
    "real_data=pd.read_csv(\"dataset/True.csv\")\n",
    "nela = NELAFeatureExtractor()\n",
    "glove_embeddings = {}\n",
    "print(\"Loading glove embeddings\")\n",
    "with open('glove.6B.100d.txt', 'r',encoding='utf8') as f:\n",
    "    for line in tqdm(f):\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        glove_embeddings[word] = vector\n",
    "test_embeddings = [\n",
    "    # Socioeconomic status\n",
    "    {'name': 'rich/poor', 'dir1': [\"rich\", \"wealthy\", \"affluent\"], \"dir2\": [\"poor\", \"impoverished\", \"destitute\"]},\n",
    "    \n",
    "    # Age bias\n",
    "    {'name': 'young/old', 'dir1': [\"young\", \"youthful\", \"vibrant\"], \"dir2\": [\"old\", \"elderly\", \"aged\"]},\n",
    "    \n",
    "    # Gender stereotypes (roles)\n",
    "    {'name': 'male/female stereotypes', 'dir1': [\"leader\", \"strong\", \"assertive\"], \"dir2\": [\"nurturing\", \"caring\", \"supportive\"]},\n",
    "    \n",
    "    # Rural vs. Urban bias\n",
    "    {'name': 'rural/urban', 'dir1': [\"urban\", \"city\"], \"dir2\": [\"rural\", \"countryside\"]},\n",
    "    \n",
    "    # Employment bias (white-collar vs. blue-collar)\n",
    "    {'name': 'white-collar/blue-collar', 'dir1': [\"professional\", \"educated\", \"executive\"], \"dir2\": [\"manual\", \"laborer\", \"working-class\"]},\n",
    "    \n",
    "    # Intelligence perception\n",
    "    {'name': 'smart/dumb', 'dir1': [\"smart\", \"intelligent\"], 'dir2': [\"dumb\", \"stupid\"]},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ee2ad31-8a8a-4acb-bd2f-a9e5eed5f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_embedding_features(inp, glove_embeddings):\n",
    "    # Find the average embedding of the sentence\n",
    "    words = inp.split()\n",
    "    embedding = np.zeros(len(glove_embeddings['the']))\n",
    "    \n",
    "    for word in words:\n",
    "        if word.lower() in glove_embeddings:\n",
    "            embedding += glove_embeddings[word.lower()]\n",
    "    embedding /= len(words)\n",
    "    \n",
    "    # Now find all cosine similarities to the difference between dir1 and dir2\n",
    "    embedding_features = []\n",
    "    embedding_names = []\n",
    "    for test_embedding in test_embeddings:\n",
    "        net_dir = np.zeros(len(glove_embeddings['the']))\n",
    "        for word in test_embedding['dir1']:\n",
    "            net_dir += glove_embeddings[word]\n",
    "        for word in test_embedding['dir2']:\n",
    "            net_dir -= glove_embeddings[word]\n",
    "        net_dir /= len(test_embedding['dir1']) + len(test_embedding['dir2'])\n",
    "        \n",
    "        # Find the cosine similarity\n",
    "        cos_sim = np.dot(embedding, net_dir) / (np.linalg.norm(embedding) * np.linalg.norm(net_dir))\n",
    "\n",
    "        embedding_features.append(cos_sim)\n",
    "        embedding_names.append(test_embedding['name'])\n",
    "        \n",
    "    return embedding_features, embedding_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9be8f6fa-fbaa-41c5-9125-6ca86f3fffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_short(df):\n",
    "    df[\"text\"] = df.text.astype(str)\n",
    "    df[\"WordsCount\"]=df[\"text\"].apply(lambda x: len(re.sub('[^a-zA-Z]', ' ', x)))\n",
    "    df=df[(df[\"WordsCount\"]>= 5)]\n",
    "    if 'id' in df.columns:\n",
    "        df = df[df['id'].str.isnumeric()]\n",
    "    df = df[df['text'].str.isnumeric() == False]\n",
    "    df = df[df['text'] != None]\n",
    "    df = df[df['text'] != ' ']\n",
    "    df = df.drop([\"WordsCount\"], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "fake_data[\"label\"]=\"fake\"\n",
    "fake_data = filter_short(fake_data)\n",
    "real_data[\"label\"]=\"real\"\n",
    "real_data = filter_short(real_data)\n",
    "\n",
    "real_data = real_data.sample(1000)\n",
    "fake_data = fake_data.sample(1000)\n",
    "\n",
    "\n",
    "final_data= pd.concat([fake_data,real_data])\n",
    "\n",
    "final_data = final_data.drop([\"subject\",\"date\"], axis=1)\n",
    "final_data=final_data[[\"text\",\"label\"]]\n",
    "final_data['label'] = final_data['label'].map({'real':1, 'fake':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2b505f2-f83d-4aa2-b859-393b50f4d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5902b6e-07e0-46ca-99d1-52453a3a564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def just_vector(text):\n",
    "    feature_vector, feature_names = nela.extract_all(text)\n",
    "    return feature_vector\n",
    "def embedding_vector(text):\n",
    "    embedding_features, embedding_names = find_embedding_features(text, glove_embeddings)\n",
    "    return embedding_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0901de5e-f7cd-4c40-948a-7d11bb58a4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514ecd2c2d534bb7ac718dc7b54c8ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname CST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "C:\\Users\\Julian\\AppData\\Local\\Temp\\ipykernel_21948\\829522840.py:23: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cos_sim = np.dot(embedding, net_dir) / (np.linalg.norm(embedding) * np.linalg.norm(net_dir))\n",
      "C:\\Users\\Julian\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname M identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "C:\\Users\\Julian\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname PST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "C:\\Users\\Julian\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "C:\\Users\\Julian\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "C:\\Users\\Julian\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname ET identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "C:\\Users\\Julian\\AppData\\Roaming\\Python\\Python310\\site-packages\\dateutil\\parser\\_parser.py:1207: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "final_data = [[just_vector(x) + embedding_vector(x),y] for x,y in tqdm(final_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a91d54f-2163-4132-b3c2-2fd05c92709e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x[0]+[x[1]] for x in final_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76ec577c-fdfd-48b1-beaa-f6eb86ea9896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 94)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98575a7f-3aa4-4639-93c1-feeb7e8b87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector, feature_names = nela.extract_all(\"hello\")\n",
    "embedding_features, embedding_names = find_embedding_features(\"hello\", glove_embeddings)\n",
    "df = pd.DataFrame(data, columns=feature_names+embedding_names+['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cce3c142-1c92-4702-b4eb-f850b43a5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split([x[0] for x in final_data], [x[1] for x in final_data], stratify = [x[1] for x in final_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c6e3ad9-d003-4495-9470-2d572c2411bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [x[0]+[x[1]] for x in list(zip(X_train,Y_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94071029-8850-4c4d-98b3-2308fd320b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [x[0]+[x[1]] for x in list(zip(X_test,Y_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65fe427d-9c02-474e-a56f-a7c4000d2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train, columns=feature_names+embedding_names+['label'])\n",
    "test_df = pd.DataFrame(test, columns=feature_names+embedding_names+['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "320cfbad-0904-426e-88e9-e7e18647adbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"dataset/fakenewstrain.csv\")\n",
    "test_df.to_csv(\"dataset/fakenewstest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f76272-8868-406c-a8a2-a7f399318a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
